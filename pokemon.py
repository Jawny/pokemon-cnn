# -*- coding: utf-8 -*-
"""pokemon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iVL9BEZoo_knWUG8jrxu24gAwPEOJ1Te
"""

!unzip "/content/drive/MyDrive/Colab Notebooks/datsets/pokemon.zip"
!unzip "/content/drive/MyDrive/Colab Notebooks/datsets/pokemon_validation.zip"

import matplotlib.pyplot as plt
import cv2
import os
import requests
import numpy as np
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Sequential, save_model, load_model
from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

# img = image.load_img("/content/PokemonData/Abra/06b9eec4827d4d49b1b4c284308708df.jpg")
# plt.imshow(img)
TRAINING_DIR = "/content/PokemonData"
TESTING_DIR = '/content/pokemon_validation'
IMG_HEIGHT, IMG_WIDTH = 512, 512
SAVE_MODEL_DIR = './content/model'
train = ImageDataGenerator(rescale=1/255)
validation = ImageDataGenerator(rescale=1/255)

train_dataset = train.flow_from_directory(TRAINING_DIR, target_size=(IMG_HEIGHT,IMG_WIDTH), batch_size=32, class_mode='categorical')
testing_dataset = train.flow_from_directory(TESTING_DIR, target_size=(IMG_HEIGHT,IMG_WIDTH), batch_size=32, class_mode='categorical')

dataset_indices = train_dataset.class_indices # shows the mapping to each class
print(dataset_indices)
# print(len(dataset_indices))

model = Sequential()

model.add(Conv2D(32, (3,3), input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64, (3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(64))

model.add(Dense(len(dataset_indices)))
model.add(Activation('softmax'))

# VGG model
# model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu', input_shape =(IMG_WIDTH,IMG_WIDTH,3), kernel_initializer = 'he_normal'))
# model.add(BatchNormalization(axis = -1))
# model.add(MaxPooling2D((2, 2)))
# model.add(Dropout(0.25))

# model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))
# model.add(BatchNormalization(axis = -1))
# model.add(Conv2D(64, (3,3), padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))
# model.add(BatchNormalization(axis = -1))
# model.add(MaxPooling2D((2, 2)))
# model.add(Dropout(0.25))

# model.add(Conv2D(128, (3,3), padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))
# model.add(BatchNormalization(axis = -1))
# model.add(Conv2D(128, (3,3), padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))
# model.add(BatchNormalization(axis = -1))
# model.add(MaxPooling2D((2, 2)))
# model.add(Dropout(0.25))

# model.add(Conv2D(256, (3,3), padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))
# model.add(BatchNormalization(axis = -1))
# model.add(Conv2D(256, (3,3), padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))
# model.add(BatchNormalization(axis = -1))
# model.add(MaxPooling2D((2, 2)))
# model.add(Dropout(0.25))

# model.add(Flatten())
# model.add(Dense(512, activation = 'relu'))
# model.add(BatchNormalization())
# model.add(Dropout(0.5))
# model.add(Dense(256, activation = 'relu'))
# model.add(BatchNormalization())
# model.add(Dropout(0.5))
# model.add(Dense(len(dataset_indices), activation = 'softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')
# mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')
# reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')

# model_fit = model.fit(train_dataset, steps_per_epoch=5, epochs=50, shuffle=True, callbacks=[earlyStopping, mcp_save, reduce_lr_loss])
model_fit = model.fit(train_dataset, steps_per_epoch=5, epochs=80, shuffle=True)

save_model(model, SAVE_MODEL_DIR)

load_model(SAVE_MODEL_DIR, compile=True)
# images = []
# # unsorted images
# for img in os.listdir(TESTING_DIR):
#   img = os.path.join(TESTING_DIR, img)
#   img = image.load_img(img, target_size=(IMG_HEIGHT, IMG_WIDTH))
#   img = image.img_to_array(img)
#   img = np.expand_dims(img, axis=0)
#   images.append(img)

# images = np.vstack(images)
# np.random.shuffle(images)

test_image = cv2.resize(cv2.imread("/content/pokemon_validation/66.png"),  (IMG_HEIGHT, IMG_WIDTH))

test_image = np.array(test_image).reshape( -1, IMG_HEIGHT, IMG_WIDTH, 3)

proba = model.predict(test_image, batch_size=128, verbose=1)
classes = proba.argmax(axis=-1)



# prediction = model.predict( test_image )
print(classes)
# print(images)
# classes = model.predict_classes(images, batch_size=10) # deprecated
# for i in range(len(classes)):
#   cv2.imread(images[i])
#   print(classes[i])
# print(classes)